# ğŸ›’ TrackBasket

A comprehensive price tracking and comparison web application that monitors products across major retailers (Amazon, Target, Walmart). TrackBasket helps users find the best deals by tracking price history, comparing prices across stores, and providing intelligent product recommendations.

## âœ¨ Features

### ğŸ¯ For Users
- **ğŸ’° Price Tracking**: Monitor price changes for your favorite products
- **ğŸ“Š Price History Charts**: Visualize price trends over time
- **ğŸ›’ Shopping Baskets**: Organize products into custom collections
- **ğŸ” Smart Search**: Find products across multiple retailers
- **ğŸ“± Modern UI**: Responsive design with dark/light theme support
- **ğŸ‘¤ User Profiles**: Personalized tracking and recommendations
- **ğŸ·ï¸ Category Browsing**: Explore products by category hierarchy
- **âš¡ Real-time Updates**: Live price updates and notifications

### ğŸ¤– Backend Intelligence
- **ğŸ•·ï¸ Automated Crawling**: Continuously monitors retailer websites
- **ğŸ” UPC Lookup**: Matches products across retailers using UPC codes
- **ğŸ“Š Data Normalization**: Standardizes product information
- **âš¡ High Performance**: Concurrent processing with intelligent rate limiting
- **ğŸ—„ï¸ Robust Storage**: Supabase backend with real-time capabilities

## ğŸ—ï¸ Architecture

```
TrackBasket/
â”œâ”€â”€ apps/web/                   # ğŸŒ Next.js Web Application
â”‚   â”œâ”€â”€ app/                   # ğŸ“± App Router Pages
â”‚   â”‚   â”œâ”€â”€ auth/             # ğŸ” Authentication pages
â”‚   â”‚   â”œâ”€â”€ baskets/          # ğŸ›’ Shopping basket management
â”‚   â”‚   â”œâ”€â”€ categories/       # ğŸ·ï¸ Product category browsing
â”‚   â”‚   â”œâ”€â”€ product/          # ğŸ“¦ Product detail pages
â”‚   â”‚   â”œâ”€â”€ profile/          # ğŸ‘¤ User profile management
â”‚   â”‚   â”œâ”€â”€ search/           # ğŸ” Product search interface
â”‚   â”‚   â””â”€â”€ settings/         # âš™ï¸ User settings
â”‚   â”œâ”€â”€ components/           # ğŸ§© React Components
â”‚   â”‚   â”œâ”€â”€ AuthForm.tsx      # ğŸ” Authentication forms
â”‚   â”‚   â”œâ”€â”€ PriceComparisonTable.tsx  # ğŸ’° Price comparison
â”‚   â”‚   â”œâ”€â”€ PriceHistoryChart.tsx     # ğŸ“Š Price trend charts
â”‚   â”‚   â”œâ”€â”€ ProductCard.tsx          # ğŸ“¦ Product display cards
â”‚   â”‚   â”œâ”€â”€ ProductTrackingForm.tsx  # ğŸ“ˆ Product tracking setup
â”‚   â”‚   â”œâ”€â”€ NavBar.tsx              # ğŸ§­ Navigation
â”‚   â”‚   â””â”€â”€ ThemeProvider.tsx       # ğŸ¨ Theme management
â”‚   â””â”€â”€ lib/                  # ğŸ“š Utilities & Configuration
â”‚       â”œâ”€â”€ auth.tsx          # ğŸ” Authentication logic
â”‚       â”œâ”€â”€ database.types.ts # ğŸ“Š TypeScript database types
â”‚       â””â”€â”€ supabaseClient.ts # ğŸ—„ï¸ Supabase client
â”œâ”€â”€ src/                       # ğŸ”§ Backend System
â”‚   â”œâ”€â”€ crawlers/             # ğŸ•·ï¸ Web crawlers for data collection
â”‚   â”‚   â”œâ”€â”€ amazon/           # ğŸ“¦ Amazon crawler
â”‚   â”‚   â”œâ”€â”€ target/           # ğŸ¯ Target crawler
â”‚   â”‚   â”œâ”€â”€ walmart/          # ğŸª Walmart crawler
â”‚   â”‚   â”œâ”€â”€ upc_lookup/       # ğŸ” UPC/barcode lookup system
â”‚   â”‚   â””â”€â”€ normalizers/      # ğŸ·ï¸ Data normalization
â”‚   â””â”€â”€ scrapers/             # ğŸ§¹ Direct product scrapers
â”œâ”€â”€ supabase/                 # ğŸ—„ï¸ Database & Backend
â”‚   â””â”€â”€ migrations/           # ğŸ”„ Database schema migrations
â”œâ”€â”€ scripts/                  # ğŸš€ Automation Scripts
â””â”€â”€ data/                     # ğŸ’¾ Category hierarchies & processed data
```

## ğŸš€ Getting Started

### ğŸ“‹ Prerequisites
- Node.js 22+ and npm/yarn
- Python 3.12+ for backend crawlers
- Supabase account (or local instance)

### ğŸƒâ€â™‚ï¸ Quick Setup

1. **Clone the repository**:
```bash
git clone <repository-url>
cd trackbasket
```

2. **Set up the web application**:
```bash
cd apps/web
npm install
```

3. **Configure environment variables**:
```bash
# In apps/web/.env.local
NEXT_PUBLIC_SUPABASE_URL=your-supabase-url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-supabase-anon-key
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key
```

4. **Set up the database**:
```bash
cd supabase
npx supabase start  # For local development
# Or configure your Supabase project and run migrations
```

5. **Install backend dependencies**:
```bash
cd ../../  # Back to project root
pip install -r requirements.txt
```

6. **Start the development server**:
```bash
cd apps/web
npm run dev
```

Visit `http://localhost:3000` to see the application!

## ğŸŒ Web Application Features

### ğŸ” Authentication
- **Sign up/Sign in**: Secure user authentication via Supabase Auth
- **Password Reset**: Email-based password recovery
- **Protected Routes**: Middleware-based route protection

### ğŸ›’ Product Management
- **Product Tracking**: Add products to track price changes
- **Shopping Baskets**: Organize products into custom collections
- **Price Alerts**: Get notified when prices drop
- **Comparison Tables**: Side-by-side price comparison across retailers

### ğŸ“Š Analytics & Insights
- **Price History Charts**: Interactive charts showing price trends
- **Best Deals**: Automatically surface the best current deals
- **Category Analytics**: Price insights by product category

### ğŸ¨ User Experience
- **Responsive Design**: Works seamlessly on desktop and mobile
- **Dark/Light Themes**: Toggle between theme preferences
- **Fast Search**: Instant product search with filters
- **Breadcrumb Navigation**: Easy navigation through categories

## ğŸ¤– Backend Crawling System

### ğŸ•·ï¸ Automated Data Collection
The backend system continuously monitors retailer websites to keep product data fresh:

```bash
# Run manual crawls for testing
python scripts/crawl.py --retailer amazon --mode full --max-pages 3
python scripts/crawl.py --retailer target --category "Beverages" --hierarchical
python scripts/crawl.py --retailer walmart --from-hierarchy-file --concurrency 10
```

### ğŸ” UPC Lookup & Matching
- **Cross-retailer Matching**: Uses UPC codes to match products across stores
- **Confidence Scoring**: Evaluates match reliability
- **Fallback Services**: Multiple UPC lookup providers
- **Intelligent Caching**: Reduces API costs and improves performance

### ğŸ“Š Data Processing
- **Category Normalization**: Standardizes product categories
- **Price History Tracking**: Maintains historical price data
- **Deduplication**: Prevents duplicate product entries
- **Real-time Updates**: Pushes updates to web app via Supabase real-time

## ğŸ—„ï¸ Database Schema

The application uses Supabase with the following core tables:
- **users**: User profiles and preferences
- **products**: Core product information with UPC codes
- **listings**: Retailer-specific product listings and prices
- **categories**: Hierarchical category structure
- **price_histories**: Historical price tracking
- **user_baskets**: User shopping basket collections

## ğŸ› ï¸ Development

### ğŸ§ª Running Tests
```bash
# Frontend tests
cd apps/web
npm test

# Backend tests
python -m pytest
```

### ğŸ”§ Adding New Retailers
1. Create crawler in `src/crawlers/{retailer}/`
2. Implement retailer-specific parsing logic
3. Add retailer configuration to scripts
4. Update database with retailer information

### ğŸ“± Frontend Development
The web app uses modern React patterns:
- **App Router**: Next.js 13+ app directory structure
- **Server Components**: Efficient server-side rendering
- **TypeScript**: Full type safety across the stack
- **Tailwind CSS**: Utility-first styling
- **Radix UI**: Accessible component primitives

## ğŸš€ Deployment

### ğŸŒ Web Application
Deploy the Next.js app to Vercel, Netlify, or your preferred platform:

```bash
cd apps/web
npm run build
```

### ğŸ¤– Backend Crawlers
Set up automated crawling with cron jobs or cloud functions:

```bash
# Example cron job for daily crawling
0 2 * * * cd /path/to/trackbasket && python scripts/crawl.py --retailer amazon --from-hierarchy-file
```

### ğŸ—„ï¸ Database
- Use Supabase hosted database for production
- Set up proper RLS (Row Level Security) policies
- Configure backups and monitoring

## ğŸ“ˆ Performance & Scaling

### âš¡ Frontend Optimization
- **Static Generation**: Pre-render category and product pages
- **Image Optimization**: Next.js automatic image optimization
- **Code Splitting**: Automatic route-based code splitting
- **Caching**: Intelligent caching with ISR (Incremental Static Regeneration)

### ğŸ”§ Backend Optimization
- **Concurrent Crawling**: Configurable worker pools
- **Rate Limiting**: Respectful crawling with intelligent delays
- **Caching**: Redis for UPC lookups and temporary data
- **Database Indexing**: Optimized queries for fast searches

## ğŸ” Security

- **Authentication**: Supabase Auth with RLS policies
- **API Security**: Protected API routes with middleware
- **Data Validation**: Input validation on both client and server
- **CAPTCHA Handling**: Automated CAPTCHA solving for crawlers

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.